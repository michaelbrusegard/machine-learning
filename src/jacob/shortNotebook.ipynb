{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d49ef1-f6b0-4500-a7eb-c5111046c6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "# Calculations\n",
    "import math\n",
    "from haversine import haversine, Unit\n",
    "from geopy.distance import geodesic\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from gluonts.torch.model.tft import TemporalFusionTransformerEstimator  # TFT from Torch\n",
    "from gluonts.torch.model.deepar import DeepAREstimator  # DeepAR from Torch\n",
    "from lightning.pytorch import Trainer  # PyTorch Lightning Trainer\n",
    "\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim  # For optimization\n",
    "\n",
    "# AutoML libraries\n",
    "from autogluon.tabular import TabularPredictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a2887-dd71-42ef-a560-cb02ff671d53",
   "metadata": {},
   "source": [
    "### Models Employed\n",
    "\\\n",
    "tabularPredictor\n",
    "\\\n",
    "GRU-D \n",
    "\\\n",
    "Both of these for one-step recurrent prediction\n",
    "\\\n",
    "TFT\n",
    "\\\n",
    "deepAR\n",
    "\\\n",
    "Both of these for sequence prediction\n",
    "\\\n",
    "These will be stacked using autogluon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c80638-f501-4230-b8fd-80759629ad94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522065 entries, 0 to 1522064\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count    Dtype  \n",
      "---  ------     --------------    -----  \n",
      " 0   time       1522065 non-null  object \n",
      " 1   cog        1522065 non-null  float64\n",
      " 2   sog        1522065 non-null  float64\n",
      " 3   rot        1522065 non-null  int64  \n",
      " 4   heading    1522065 non-null  int64  \n",
      " 5   navstat    1522065 non-null  int64  \n",
      " 6   etaRaw     1522065 non-null  object \n",
      " 7   latitude   1522065 non-null  float64\n",
      " 8   longitude  1522065 non-null  float64\n",
      " 9   vesselId   1522065 non-null  object \n",
      " 10  portId     1520450 non-null  object \n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 127.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your file in the bucket\n",
    "file_path = 'gs://jacobsbucketformlproject/ML Competition/ais_train.csv'\n",
    "\n",
    "# Load the file into a pandas dataframe\n",
    "ais_train_df = pd.read_csv(file_path, delimiter= '|', encoding= 'utf-8')\n",
    "\n",
    "# Display the dataframe\n",
    "ais_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1f7b1-4a3c-4372-9ea0-0c6647f94499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51739 entries, 0 to 51738\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ID              51739 non-null  int64  \n",
      " 1   vesselId        51739 non-null  object \n",
      " 2   time            51739 non-null  object \n",
      " 3   scaling_factor  51739 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "ais_test_df = pd.read_csv('gs://jacobsbucketformlproject/ML Competition/ais_test.csv')\n",
    "ais_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b31dbc-e3f3-47c1-9b44-122c4a57792d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1329 entries, 0 to 1328\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   portId        1329 non-null   object \n",
      " 1   name          1329 non-null   object \n",
      " 2   portLocation  1329 non-null   object \n",
      " 3   longitude     1329 non-null   float64\n",
      " 4   latitude      1329 non-null   float64\n",
      " 5   UN_LOCODE     1329 non-null   object \n",
      " 6   countryName   1329 non-null   object \n",
      " 7   ISO           1329 non-null   object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 83.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your file in the bucket\n",
    "file_path = 'gs://jacobsbucketformlproject/ML Competition/ports.csv'\n",
    "\n",
    "#Load the file into a pandas dataframe\n",
    "ports_df = pd.read_csv(file_path, delimiter= '|', encoding= 'utf-8')\n",
    "\n",
    "ports_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905df1ee-9403-42c8-b9e4-341e17dc2170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 711 entries, 0 to 710\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   shippingLineId  711 non-null    object \n",
      " 1   vesselId        711 non-null    object \n",
      " 2   CEU             711 non-null    int64  \n",
      " 3   DWT             703 non-null    float64\n",
      " 4   GT              711 non-null    int64  \n",
      " 5   NT              187 non-null    float64\n",
      " 6   vesselType      699 non-null    float64\n",
      " 7   breadth         703 non-null    float64\n",
      " 8   depth           242 non-null    float64\n",
      " 9   draft           10 non-null     float64\n",
      " 10  enginePower     691 non-null    float64\n",
      " 11  freshWater      221 non-null    float64\n",
      " 12  fuel            221 non-null    float64\n",
      " 13  homePort        573 non-null    object \n",
      " 14  length          711 non-null    float64\n",
      " 15  maxHeight       35 non-null     float64\n",
      " 16  maxSpeed        213 non-null    float64\n",
      " 17  maxWidth        35 non-null     float64\n",
      " 18  rampCapacity    34 non-null     float64\n",
      " 19  yearBuilt       711 non-null    int64  \n",
      "dtypes: float64(14), int64(3), object(3)\n",
      "memory usage: 111.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your file in the bucket\n",
    "file_path = 'gs://jacobsbucketformlproject/ML Competition/vessels.csv'\n",
    "\n",
    "#Load the file into a pandas dataframe\n",
    "vessels_df = pd.read_csv(file_path, delimiter= '|', encoding= 'utf-8')\n",
    "\n",
    "vessels_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8443323-6694-40d7-a014-e9f1b3d95cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the path to your file in the bucket\n",
    "file_path = 'gs://jacobsbucketformlproject/ML Competition/schedules_to_may_2024.csv'\n",
    "\n",
    "#Load the file into a pandas dataframe\n",
    "schedules_df = pd.read_csv(file_path, delimiter= '|', encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72b6c1a-7511-4310-b95b-b1d46438b58a",
   "metadata": {},
   "source": [
    "# We pre-process ais_train and combine it with the relevant features from ports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ccbcd8-8d1b-40b9-a575-2df69deeb712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 portId values from ais_train_df do not exist in ports_df.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522065 entries, 0 to 1522064\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   time           1522065 non-null  datetime64[ns]\n",
      " 1   cog            1516207 non-null  float64       \n",
      " 2   sog            1522065 non-null  float64       \n",
      " 3   rot            1522065 non-null  float64       \n",
      " 4   heading        1517169 non-null  float64       \n",
      " 5   navstat        1522065 non-null  int64         \n",
      " 6   etaRaw         766829 non-null   datetime64[ns]\n",
      " 7   latitude       1522065 non-null  float64       \n",
      " 8   longitude      1522065 non-null  float64       \n",
      " 9   vesselId       1522065 non-null  object        \n",
      " 10  portId         1520450 non-null  object        \n",
      " 11  portLatitude   1520450 non-null  float64       \n",
      " 12  portLongitude  1520450 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(8), int64(1), object(2)\n",
      "memory usage: 151.0+ MB\n"
     ]
    }
   ],
   "source": [
    "def preprocess_ais_train(ais_train_df, ports_df):\n",
    "    \"\"\"\n",
    "    Preprocess the ais_train_df by converting columns, handling missing or invalid values, \n",
    "    merging port information, and mapping NAVSTAT codes to descriptions.\n",
    "    \n",
    "    Additionally, set 'etaRaw' to NaN if its value is less than the current time.\n",
    "\n",
    "    Parameters:\n",
    "    - ais_train_df: DataFrame containing the raw AIS train data.\n",
    "    - ports_df: DataFrame containing port information with portId, latitude, and longitude.\n",
    "\n",
    "    Returns:\n",
    "    - ais_train_df_cleaned: A cleaned and preprocessed version of ais_train_df.\n",
    "    \"\"\"\n",
    "    # Step 1: Convert 'time' and 'etaRaw' to datetime\n",
    "    ais_train_df['time'] = pd.to_datetime(ais_train_df['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    ais_train_df['etaRaw'] = pd.to_datetime(ais_train_df['etaRaw'], errors='coerce', format='%m-%d %H:%M')\n",
    "    \n",
    "    # Step 2: Add the year 2024 to 'etaRaw' column\n",
    "    ais_train_df['etaRaw'] = ais_train_df['etaRaw'].apply(lambda x: x.replace(year=2024) if pd.notna(x) else pd.NaT)\n",
    "\n",
    "    # Step 3: Set etaRaw to NaN if etaRaw is less than the current time\n",
    "    current_time = pd.Timestamp.now()\n",
    "    ais_train_df['etaRaw'] = ais_train_df.apply(lambda row: row['etaRaw'] if pd.isna(row['etaRaw']) or row['etaRaw'] >= row['time'] else pd.NaT, axis=1)\n",
    "\n",
    "    # Step 4: Convert relevant columns to float\n",
    "    ais_train_df['cog'] = ais_train_df['cog'].astype(float)\n",
    "    ais_train_df['sog'] = ais_train_df['sog'].astype(float)\n",
    "    ais_train_df['rot'] = ais_train_df['rot'].astype(float)\n",
    "    ais_train_df['heading'] = ais_train_df['heading'].astype(float)\n",
    "    ais_train_df['latitude'] = ais_train_df['latitude'].astype(float)\n",
    "    ais_train_df['longitude'] = ais_train_df['longitude'].astype(float)\n",
    "    \n",
    "    # Step 5: Replace invalid or default values with NaN\n",
    "    ais_train_df['cog'] = np.where((ais_train_df['cog'] == 360) | (ais_train_df['cog'] > 360) | (ais_train_df['cog'] < 0), np.nan, ais_train_df['cog'])\n",
    "    ais_train_df['sog'] = np.where((ais_train_df['sog'] == 1023) | (ais_train_df['sog'] < 0), np.nan, ais_train_df['sog'])\n",
    "    ais_train_df['rot'] = np.where((ais_train_df['rot'] == -128), np.nan, ais_train_df['rot'])\n",
    "    ais_train_df['heading'] = np.where((ais_train_df['heading'] > 360) | (ais_train_df['heading'] == 511) | (ais_train_df['heading'] < 0), np.nan, ais_train_df['heading'])\n",
    "\n",
    "    # Step 6: Merge with ports to get port latitude and longitude\n",
    "\n",
    "    # Renaming the latitude and longitude columns in ports_df to portLatitude and portLongitude\n",
    "    ports_df = ports_df.rename(columns={'latitude': 'portLatitude', 'longitude': 'portLongitude'})\n",
    "\n",
    "    # Checking for missing portId values and printing for reference\n",
    "    missing_in_ports = set(ais_train_df['portId']) - set(ports_df['portId'])\n",
    "    if len(missing_in_ports) > 0:\n",
    "        print(f\"Warning: {len(missing_in_ports)} portId values from ais_train_df do not exist in ports_df.\")\n",
    "    \n",
    "    # Merging ais_train_df with the updated ports_df on 'portId'\n",
    "    ais_train_df = ais_train_df.merge(ports_df[['portId', 'portLatitude', 'portLongitude']], on='portId', how='left')\n",
    "    \n",
    "    # Step 7: Sort by vesselId and time\n",
    "    ais_train_df = ais_train_df.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "\n",
    "    return ais_train_df\n",
    "\n",
    "ais_train_df = preprocess_ais_train(ais_train_df, ports_df)\n",
    "\n",
    "ais_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db667999-8e0e-4706-97f4-544dbd16cdd2",
   "metadata": {},
   "source": [
    "# We now pre-process the vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd2d45d-26bc-4de2-af26-b92af62e9c23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 711 entries, 0 to 710\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   shippingLineId  711 non-null    object  \n",
      " 1   vesselId        711 non-null    object  \n",
      " 2   CEU             711 non-null    int64   \n",
      " 3   DWT             711 non-null    float64 \n",
      " 4   GT              711 non-null    int64   \n",
      " 5   vesselType      711 non-null    category\n",
      " 6   breadth         711 non-null    float64 \n",
      " 7   homePort        711 non-null    object  \n",
      " 8   length          711 non-null    float64 \n",
      " 9   age             711 non-null    int64   \n",
      "dtypes: category(1), float64(3), int64(3), object(3)\n",
      "memory usage: 51.0+ KB\n"
     ]
    }
   ],
   "source": [
    "def preprocess_vessels(vessels_df):\n",
    "    \"\"\"\n",
    "    Preprocess the vessels_df by converting 'yearBuilt' to 'age', handling missing values, \n",
    "    mapping 'homePort', and converting 'shippingLineId' into a categorical feature.\n",
    "    \n",
    "    Parameters:\n",
    "    - vessels_df: DataFrame containing the raw vessels data.\n",
    "    \n",
    "    Returns:\n",
    "    - vessels_df_cleaned: A cleaned and preprocessed version of vessels_df.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Convert 'yearBuilt' to 'age'\n",
    "    current_year = 2024\n",
    "    vessels_df['age'] = vessels_df['yearBuilt'].apply(lambda x: current_year - x if pd.notna(x) else np.nan)\n",
    "    vessels_df.drop(columns=['yearBuilt'], inplace=True)\n",
    "    \n",
    "    # Step 2: Drop columns with high missing values and low predictive power\n",
    "    columns_to_drop = ['NT', 'depth', 'draft', 'freshWater', 'enginePower', 'fuel', \n",
    "                       'maxHeight', 'maxWidth', 'rampCapacity', 'maxSpeed']\n",
    "    vessels_df.drop(columns=columns_to_drop, inplace=True)\n",
    "    \n",
    "    # Step 3: Make vesselType into category\n",
    "    # Convert 'vesselType' from float to categorical without knowing the exact mapping\n",
    "    vessels_df['vesselType'] = vessels_df['vesselType'].astype('category')\n",
    "\n",
    "    # Optionally, handle missing values (nan) by filling them with 'Unknown' or leaving them as is\n",
    "    vessels_df['vesselType'] = vessels_df['vesselType'].cat.add_categories('Unknown').fillna('Unknown')\n",
    "    \n",
    "    return vessels_df\n",
    "\n",
    "\n",
    "def map_homePort_to_country(vessels_df):\n",
    "    \"\"\"\n",
    "    Maps 'homePort' city names to their respective countries and groups rare countries into 'OTHER'.\n",
    "    \"\"\"\n",
    "    initial_mapping = {\n",
    "        'PANAMA': 'Panama', 'UNKNOWN': 'Unknown', 'PALERMO': 'Italy', 'NASSAU': 'Bahamas', \n",
    "        'TOKYO': 'Japan', 'VALLETTA': 'Malta', 'OSLO': 'Norway', 'MONROVIA': 'Liberia', \n",
    "        'MAJURO': 'Marshall Islands', 'JEJU CHEJU': 'South Korea', 'HELSINKI': 'Finland',\n",
    "        # Add other mappings here...\n",
    "    }\n",
    "    \n",
    "    vessels_df['homePort'] = vessels_df['homePort'].map(initial_mapping).fillna('OTHER')\n",
    "    \n",
    "    # Group rare countries into 'OTHER' (with fewer than 10 occurrences)\n",
    "    country_counts = vessels_df['homePort'].value_counts()\n",
    "    rare_countries = country_counts[country_counts < 10].index.tolist()\n",
    "    vessels_df['homePort'] = vessels_df['homePort'].replace(rare_countries, 'OTHER')\n",
    "    \n",
    "    return vessels_df\n",
    "\n",
    "\n",
    "def process_shippingLineId(vessels_df):\n",
    "    \"\"\"\n",
    "    Converts 'shippingLineId' into a categorical feature, grouping those with less than 13 occurrences \n",
    "    into 'Unknown'.\n",
    "    \"\"\"\n",
    "    # Calculate the frequency of each shippingLineId\n",
    "    shipping_freq = vessels_df['shippingLineId'].value_counts()\n",
    "    \n",
    "    # Map rare shippingLineIds (occurring less than 13 times) to 'Unknown'\n",
    "    vessels_df['shippingLineId'] = vessels_df['shippingLineId'].apply(\n",
    "        lambda x: x if shipping_freq[x] >= 13 else 'Unknown')\n",
    "    \n",
    "    return vessels_df\n",
    "\n",
    "\n",
    "def knn_impute_data(vessels_df, numerical_features, predictor_features, n_neighbors=10):\n",
    "    \"\"\"\n",
    "    Performs KNN imputation on the specified numerical features using the predictor features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare DataFrame for imputation\n",
    "    imputation_df = vessels_df[numerical_features + predictor_features].copy()\n",
    "    \n",
    "    # Ensure that only numerical columns are included for scaling and imputation\n",
    "    imputation_df = imputation_df.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    imputation_df[numerical_features] = scaler.fit_transform(imputation_df[numerical_features])\n",
    "    \n",
    "    # Apply KNN Imputer\n",
    "    knn_imputer = KNNImputer(n_neighbors=n_neighbors, weights=\"distance\")\n",
    "    imputed_values = knn_imputer.fit_transform(imputation_df)\n",
    "    \n",
    "    # Convert imputed values back to DataFrame and rescale\n",
    "    imputed_df = pd.DataFrame(imputed_values, columns=numerical_features + predictor_features)\n",
    "    imputed_df[numerical_features] = scaler.inverse_transform(imputed_df[numerical_features])\n",
    "    \n",
    "    # Assign imputed values back to the original vessel DataFrame\n",
    "    for feature in numerical_features:\n",
    "        vessels_df[feature] = imputed_df[feature]\n",
    "    \n",
    "    return vessels_df\n",
    "\n",
    "\n",
    "# Main Preprocessing Pipeline\n",
    "def preprocess_all(vessels_df):\n",
    "    \"\"\"\n",
    "    Full preprocessing pipeline for vessels_df including handling shippingLineId, homePort,\n",
    "    KNN imputation, and maxSpeed adjustments.\n",
    "    \"\"\"\n",
    "    # Step 1: Basic preprocessing (convert yearBuilt to age and drop unnecessary columns)\n",
    "    vessels_df = preprocess_vessels(vessels_df)\n",
    "    \n",
    "    # Step 2: Map 'homePort' to country\n",
    "    vessels_df = map_homePort_to_country(vessels_df)\n",
    "    \n",
    "    # Step 3: Convert 'shippingLineId' to categorical with grouping of rare values\n",
    "    vessels_df = process_shippingLineId(vessels_df)\n",
    "    \n",
    "    # Step 4: Impute missing numerical features\n",
    "    numerical_features = ['DWT', 'breadth']\n",
    "    predictor_features = ['CEU', 'GT', 'length', 'age']  # Exclude non-numeric features\n",
    "    vessels_df = knn_impute_data(vessels_df, numerical_features, predictor_features)\n",
    "    \n",
    "    return vessels_df\n",
    "\n",
    "\n",
    "# Apply the full pipeline\n",
    "vessels_df = preprocess_all(vessels_df)\n",
    "vessels_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1262c166-a392-4172-91ce-a06fe21c2916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83.0, 'Unknown', 21.0, 14.0]\n",
      "Categories (4, object): [14.0, 21.0, 83.0, 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values to understand the categories\n",
    "print(vessels_df['vesselType'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dddf24-363c-40ad-8549-701ea181e2cd",
   "metadata": {},
   "source": [
    "### Wait with schedules for now, as only 67 of schedules are for vessels in test set, and there are few schedules that match with ais, hence, a lot of Nan values. Perhaps use it for common ports or routes, but I feel like we could get this more realiably from the ais data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6efea-80d0-41a6-9a58-b30ebacb14e7",
   "metadata": {},
   "source": [
    "# We now merge vessel data with ais to get a base dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c251ab7-fa45-49e5-bc19-a6d6b14c6ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_ais_with_vessels(ais_data, vessel_data):\n",
    "    \"\"\"\n",
    "    Merges the AIS data with the vessel data on 'vesselId' using a left join.\n",
    "    \n",
    "    Parameters:\n",
    "    - ais_data (pd.DataFrame): DataFrame containing AIS data.\n",
    "    - vessel_data (pd.DataFrame): DataFrame containing vessel data.\n",
    "    \n",
    "    Returns:\n",
    "    - baseDataset (pd.DataFrame): Merged DataFrame containing the AIS data with vessel information.\n",
    "    \"\"\"\n",
    "    # Perform a left merge on 'vesselId'\n",
    "    baseDataset = pd.merge(ais_data, vessel_data, how='left', on='vesselId')\n",
    "    \n",
    "    return baseDataset\n",
    "\n",
    "# Example usage:\n",
    "baseDataset = merge_ais_with_vessels(ais_train_df, vessels_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e4c88c-ba10-42b7-b6b4-e08889e96672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522065 entries, 0 to 1522064\n",
      "Data columns (total 22 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   time            1522065 non-null  datetime64[ns]\n",
      " 1   cog             1516207 non-null  float64       \n",
      " 2   sog             1522065 non-null  float64       \n",
      " 3   rot             1522065 non-null  float64       \n",
      " 4   heading         1517169 non-null  float64       \n",
      " 5   navstat         1522065 non-null  int64         \n",
      " 6   etaRaw          766829 non-null   datetime64[ns]\n",
      " 7   latitude        1522065 non-null  float64       \n",
      " 8   longitude       1522065 non-null  float64       \n",
      " 9   vesselId        1522065 non-null  object        \n",
      " 10  portId          1520450 non-null  object        \n",
      " 11  portLatitude    1520450 non-null  float64       \n",
      " 12  portLongitude   1520450 non-null  float64       \n",
      " 13  shippingLineId  1522065 non-null  object        \n",
      " 14  CEU             1522065 non-null  int64         \n",
      " 15  DWT             1522065 non-null  float64       \n",
      " 16  GT              1522065 non-null  int64         \n",
      " 17  vesselType      1522065 non-null  category      \n",
      " 18  breadth         1522065 non-null  float64       \n",
      " 19  homePort        1522065 non-null  object        \n",
      " 20  length          1522065 non-null  float64       \n",
      " 21  age             1522065 non-null  int64         \n",
      "dtypes: category(1), datetime64[ns](2), float64(11), int64(4), object(4)\n",
      "memory usage: 245.3+ MB\n"
     ]
    }
   ],
   "source": [
    "baseDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d74c86-99b2-4b8a-90df-2ac59ba4f8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>rot</th>\n",
       "      <th>heading</th>\n",
       "      <th>navstat</th>\n",
       "      <th>etaRaw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>...</th>\n",
       "      <th>portLongitude</th>\n",
       "      <th>shippingLineId</th>\n",
       "      <th>CEU</th>\n",
       "      <th>DWT</th>\n",
       "      <th>GT</th>\n",
       "      <th>vesselType</th>\n",
       "      <th>breadth</th>\n",
       "      <th>homePort</th>\n",
       "      <th>length</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-12 14:07:47</td>\n",
       "      <td>308.1</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.50361</td>\n",
       "      <td>77.58340</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>...</td>\n",
       "      <td>80.341111</td>\n",
       "      <td>61a8e672f9cba188601e84ab</td>\n",
       "      <td>6500</td>\n",
       "      <td>21200.0</td>\n",
       "      <td>58684</td>\n",
       "      <td>83.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Norway</td>\n",
       "      <td>199.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-12 14:31:00</td>\n",
       "      <td>307.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-14 23:30:00</td>\n",
       "      <td>7.57302</td>\n",
       "      <td>77.49505</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>...</td>\n",
       "      <td>72.885278</td>\n",
       "      <td>61a8e672f9cba188601e84ab</td>\n",
       "      <td>6500</td>\n",
       "      <td>21200.0</td>\n",
       "      <td>58684</td>\n",
       "      <td>83.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Norway</td>\n",
       "      <td>199.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-12 14:57:23</td>\n",
       "      <td>306.8</td>\n",
       "      <td>16.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-14 23:30:00</td>\n",
       "      <td>7.65043</td>\n",
       "      <td>77.39404</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>...</td>\n",
       "      <td>72.885278</td>\n",
       "      <td>61a8e672f9cba188601e84ab</td>\n",
       "      <td>6500</td>\n",
       "      <td>21200.0</td>\n",
       "      <td>58684</td>\n",
       "      <td>83.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Norway</td>\n",
       "      <td>199.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-12 15:18:48</td>\n",
       "      <td>307.9</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-14 23:30:00</td>\n",
       "      <td>7.71275</td>\n",
       "      <td>77.31394</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>...</td>\n",
       "      <td>72.885278</td>\n",
       "      <td>61a8e672f9cba188601e84ab</td>\n",
       "      <td>6500</td>\n",
       "      <td>21200.0</td>\n",
       "      <td>58684</td>\n",
       "      <td>83.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Norway</td>\n",
       "      <td>199.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-12 15:39:47</td>\n",
       "      <td>307.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-14 23:30:00</td>\n",
       "      <td>7.77191</td>\n",
       "      <td>77.23585</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8b</td>\n",
       "      <td>...</td>\n",
       "      <td>72.885278</td>\n",
       "      <td>61a8e672f9cba188601e84ab</td>\n",
       "      <td>6500</td>\n",
       "      <td>21200.0</td>\n",
       "      <td>58684</td>\n",
       "      <td>83.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Norway</td>\n",
       "      <td>199.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    cog   sog  rot  heading  navstat              etaRaw  \\\n",
       "0 2024-01-12 14:07:47  308.1  17.1 -6.0    316.0        0                 NaT   \n",
       "1 2024-01-12 14:31:00  307.6  17.3  5.0    313.0        0 2024-01-14 23:30:00   \n",
       "2 2024-01-12 14:57:23  306.8  16.9  5.0    312.0        0 2024-01-14 23:30:00   \n",
       "3 2024-01-12 15:18:48  307.9  16.9  6.0    313.0        0 2024-01-14 23:30:00   \n",
       "4 2024-01-12 15:39:47  307.0  16.3  7.0    313.0        0 2024-01-14 23:30:00   \n",
       "\n",
       "   latitude  longitude                  vesselId  ... portLongitude  \\\n",
       "0   7.50361   77.58340  61e9f38eb937134a3c4bfd8b  ...     80.341111   \n",
       "1   7.57302   77.49505  61e9f38eb937134a3c4bfd8b  ...     72.885278   \n",
       "2   7.65043   77.39404  61e9f38eb937134a3c4bfd8b  ...     72.885278   \n",
       "3   7.71275   77.31394  61e9f38eb937134a3c4bfd8b  ...     72.885278   \n",
       "4   7.77191   77.23585  61e9f38eb937134a3c4bfd8b  ...     72.885278   \n",
       "\n",
       "             shippingLineId   CEU      DWT     GT  vesselType  breadth  \\\n",
       "0  61a8e672f9cba188601e84ab  6500  21200.0  58684        83.0     32.0   \n",
       "1  61a8e672f9cba188601e84ab  6500  21200.0  58684        83.0     32.0   \n",
       "2  61a8e672f9cba188601e84ab  6500  21200.0  58684        83.0     32.0   \n",
       "3  61a8e672f9cba188601e84ab  6500  21200.0  58684        83.0     32.0   \n",
       "4  61a8e672f9cba188601e84ab  6500  21200.0  58684        83.0     32.0   \n",
       "\n",
       "  homePort  length age  \n",
       "0   Norway   199.0  24  \n",
       "1   Norway   199.0  24  \n",
       "2   Norway   199.0  24  \n",
       "3   Norway   199.0  24  \n",
       "4   Norway   199.0  24  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26af3a-523a-43e8-8ba1-1588c692b2b1",
   "metadata": {},
   "source": [
    "# We now remove anomalies and impute some missing values for this dataset before moving onto feature engineering\n",
    "This includes removing vessels with very few records\n",
    "Flagging unusually large gaps and getting time diff feature\n",
    "Fixing sog values\n",
    "Fixing cog values\n",
    "Fixing heading values\n",
    "Fixing rot values\n",
    "generalizing navstat to fewer more meaningful values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c07fe-7d0b-4d92-a150-7cbb3ef1f373",
   "metadata": {},
   "source": [
    "We check to see the vessels with least records, and whether they are inn test set, and hence must be in dataset! If we find few records we remove them from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c21c0cfb-42b8-4bec-aed0-3d240d3c9091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    vesselId  record_count  in_test_set\n",
      "0   61e9f3cbb937134a3c4bff09             1        False\n",
      "1   61e9f3adb937134a3c4bfe37            31        False\n",
      "2   61e9f3c6b937134a3c4bfed5           160        False\n",
      "3   61e9f42cb937134a3c4c00f9           191        False\n",
      "4   61e9f45cb937134a3c4c022b           196        False\n",
      "5   61e9f39ab937134a3c4bfdb9           197        False\n",
      "6   61e9f45eb937134a3c4c0235           250        False\n",
      "7   61e9f3bcb937134a3c4bfe91           328         True\n",
      "8   61e9f418b937134a3c4c0077           332        False\n",
      "9   61e9f408b937134a3c4c0023           355        False\n",
      "10  61e9f460b937134a3c4c0243           361        False\n",
      "11  61e9f3f7b937134a3c4bffc5           373        False\n",
      "12  61e9f409b937134a3c4c0027           391        False\n",
      "13  620bf33a718775aca4a81900           401        False\n",
      "14  61e9f423b937134a3c4c00c7           402        False\n",
      "15  61e9f38eb937134a3c4bfd8b           402        False\n",
      "16  61e9f456b937134a3c4c0203           408        False\n",
      "17  61e9f3afb937134a3c4bfe47           416        False\n",
      "18  61e9f3bab937134a3c4bfe8b           451        False\n",
      "19  6326eed6c46d6a20d22ca319           451         True\n"
     ]
    }
   ],
   "source": [
    "# Get the unique vesselIds from the test set\n",
    "vessel_ids_test = set(ais_test_df['vesselId'].unique())\n",
    "\n",
    "# Get the count of records per vesselId in the training set\n",
    "vessel_record_counts = ais_train_df['vesselId'].value_counts()\n",
    "\n",
    "# Get the 10 vessels with the lowest number of records\n",
    "lowest_record_vessels = vessel_record_counts.nsmallest(20)\n",
    "\n",
    "# Check if these vessels are in the test set\n",
    "vessels_in_test = lowest_record_vessels.index.isin(vessel_ids_test)\n",
    "\n",
    "# Combine the results into a dataframe for easy viewing\n",
    "vessels_with_low_records = pd.DataFrame({\n",
    "    'vesselId': lowest_record_vessels.index,\n",
    "    'record_count': lowest_record_vessels.values,\n",
    "    'in_test_set': vessels_in_test\n",
    "})\n",
    "\n",
    "# Display the result\n",
    "print(vessels_with_low_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf33d5f-ec86-4377-ae63-91486ffdf1d8",
   "metadata": {},
   "source": [
    "We remove the two vessels with the lowest records count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d26ec89-b8f5-427c-a5e2-54429fbc4a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of vessel IDs to remove\n",
    "vessels_to_remove = ['61e9f3cbb937134a3c4bff09', '61e9f3adb937134a3c4bfe37']\n",
    "\n",
    "# Remove vessels from the dataset\n",
    "baseDataset = baseDataset[~ais_train_df['vesselId'].isin(vessels_to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d39dab-5e35-428f-8a93-12c9e7e1979e",
   "metadata": {},
   "source": [
    "We now create a time_diff column and flag large time gaps column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "985d9b90-e21e-43ea-a170-7804081756cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_time_diff_and_gap_flag(df, time_col='time', vessel_col='vesselId', threshold=2):\n",
    "    \"\"\"\n",
    "    Adds time_diff and large_gap_flag to the dataframe based on vessel-specific statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing vesselId and timestamp columns.\n",
    "    time_col (str): The name of the timestamp column.\n",
    "    vessel_col (str): The name of the vessel identifier column.\n",
    "    threshold (float): The number of standard deviations above the mean to flag large time gaps.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The original dataframe with 'time_diff' and 'large_gap_flag' added.\n",
    "    \"\"\"\n",
    "    # Ensure the time column is in datetime format\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    \n",
    "    # Calculate time_diff (difference in time between consecutive entries for each vessel)\n",
    "    df['time_diff'] = df.groupby(vessel_col)[time_col].diff().dt.total_seconds().fillna(0)\n",
    "    \n",
    "    # Group by vesselId to calculate the mean and standard deviation of time_diff for each vessel\n",
    "    vessel_stats = df.groupby(vessel_col)['time_diff'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    # Merge vessel statistics back to the original dataframe\n",
    "    df = df.merge(vessel_stats, on=vessel_col, how='left')\n",
    "    \n",
    "    # Define a large time gap as threshold * standard deviations above the mean for each vessel\n",
    "    df['large_gap_flag'] = (df['time_diff'] > df['mean'] + threshold * df['std']).astype(int)\n",
    "    \n",
    "    # Drop the mean and std columns (optional, you can keep them if needed)\n",
    "    df = df.drop(columns=['mean', 'std'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9ea4d98-e43d-43f9-8957-dd757331415c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522033 entries, 0 to 1522032\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   time            1522033 non-null  datetime64[ns]\n",
      " 1   cog             1516175 non-null  float64       \n",
      " 2   sog             1522033 non-null  float64       \n",
      " 3   rot             1522033 non-null  float64       \n",
      " 4   heading         1517137 non-null  float64       \n",
      " 5   navstat         1522033 non-null  int64         \n",
      " 6   etaRaw          766797 non-null   datetime64[ns]\n",
      " 7   latitude        1522033 non-null  float64       \n",
      " 8   longitude       1522033 non-null  float64       \n",
      " 9   vesselId        1522033 non-null  object        \n",
      " 10  portId          1520418 non-null  object        \n",
      " 11  portLatitude    1520418 non-null  float64       \n",
      " 12  portLongitude   1520418 non-null  float64       \n",
      " 13  shippingLineId  1522033 non-null  object        \n",
      " 14  CEU             1522033 non-null  int64         \n",
      " 15  DWT             1522033 non-null  float64       \n",
      " 16  GT              1522033 non-null  int64         \n",
      " 17  vesselType      1522033 non-null  category      \n",
      " 18  breadth         1522033 non-null  float64       \n",
      " 19  homePort        1522033 non-null  object        \n",
      " 20  length          1522033 non-null  float64       \n",
      " 21  age             1522033 non-null  int64         \n",
      " 22  time_diff       1522033 non-null  float64       \n",
      " 23  large_gap_flag  1522033 non-null  int64         \n",
      "dtypes: category(1), datetime64[ns](2), float64(12), int64(5), object(4)\n",
      "memory usage: 268.5+ MB\n"
     ]
    }
   ],
   "source": [
    "baseDataset = add_time_diff_and_gap_flag(baseDataset, time_col='time', vessel_col='vesselId', threshold=3)\n",
    "baseDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb21a05-af79-4d1d-8132-72c6112808ef",
   "metadata": {},
   "source": [
    "# We now generalize the navstat for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df05755e-5f1d-4616-90fe-5d5354ee736d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_navstat_to_movement(df, navstat_col='navstat'):\n",
    "    \"\"\"\n",
    "    Create a new feature indicating whether the vessel is moving, anchored, or moored \n",
    "    based on the navstat column and then remove the original navstat column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing the navstat column.\n",
    "    navstat_col (str): The name of the navstat column.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The dataframe with a new 'vessel_status' column and without the original 'navstat' column.\n",
    "    \"\"\"\n",
    "    # Define the mapping of navstat codes to the movement categories\n",
    "    navstat_mapping = {\n",
    "        0: 'moving',      # Underway using engine\n",
    "        1: 'anchored',    # Anchored\n",
    "        2: 'unknown',      # Not under command\n",
    "        3: 'moving',      # Restricted manoeuverability\n",
    "        4: 'moving',      # Constrained by her draught\n",
    "        5: 'moored',      # Moored\n",
    "        6: 'anchored',    # Aground (considered stationary)\n",
    "        7: 'moving',      # Engaged in fishing\n",
    "        8: 'moving',      # Underway sailing\n",
    "        9: 'unknown',      # Reserved for future use\n",
    "        15: 'unknown'      # Undefined\n",
    "    }\n",
    "\n",
    "    # Create a new column based on the mapping\n",
    "    df['vessel_status'] = df[navstat_col].map(navstat_mapping)\n",
    "\n",
    "    # Remove the original navstat column\n",
    "    df = df.drop(columns=[navstat_col])\n",
    "\n",
    "    return df\n",
    "\n",
    "#Apply the function to create the vessel_status feature and remove the navstat column\n",
    "baseDataset = map_navstat_to_movement(baseDataset, navstat_col='navstat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "295f9ad0-4d22-4883-a1ae-14e82c1a08f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522033 entries, 0 to 1522032\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   time            1522033 non-null  datetime64[ns]\n",
      " 1   cog             1516175 non-null  float64       \n",
      " 2   sog             1522033 non-null  float64       \n",
      " 3   rot             1522033 non-null  float64       \n",
      " 4   heading         1517137 non-null  float64       \n",
      " 5   etaRaw          766797 non-null   datetime64[ns]\n",
      " 6   latitude        1522033 non-null  float64       \n",
      " 7   longitude       1522033 non-null  float64       \n",
      " 8   vesselId        1522033 non-null  object        \n",
      " 9   portId          1520418 non-null  object        \n",
      " 10  portLatitude    1520418 non-null  float64       \n",
      " 11  portLongitude   1520418 non-null  float64       \n",
      " 12  shippingLineId  1522033 non-null  object        \n",
      " 13  CEU             1522033 non-null  int64         \n",
      " 14  DWT             1522033 non-null  float64       \n",
      " 15  GT              1522033 non-null  int64         \n",
      " 16  vesselType      1522033 non-null  category      \n",
      " 17  breadth         1522033 non-null  float64       \n",
      " 18  homePort        1522033 non-null  object        \n",
      " 19  length          1522033 non-null  float64       \n",
      " 20  age             1522033 non-null  int64         \n",
      " 21  time_diff       1522033 non-null  float64       \n",
      " 22  large_gap_flag  1522033 non-null  int64         \n",
      " 23  vessel_status   1522029 non-null  object        \n",
      "dtypes: category(1), datetime64[ns](2), float64(12), int64(4), object(5)\n",
      "memory usage: 268.5+ MB\n"
     ]
    }
   ],
   "source": [
    "baseDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0698c63f-d285-497b-b7e1-ffd3de769f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_unknown_vessel_status(df, distance_threshold=0.2):\n",
    "    \"\"\"Impute 'unknown' vessel statuses based on the following logic:\n",
    "    1. vessel_status is 'moored' and sog > 0.2,\n",
    "    2. vessel_status is 'anchored' and sog > 0.2,\n",
    "    3. vessel_status is 'moving' and sog == 0,\n",
    "    4. vessel_status is 'unknown': Impute as follows:\n",
    "        - If vessel is close to the port (within distance_threshold) and SOG = 0, set vessel_status to 'moored'.\n",
    "        - If vessel is far from port and latitude/longitude are not consistent between previous/next rows, set vessel_status to 'moving'.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing vessel_status, sog, latitude, longitude, and port information.\n",
    "    distance_threshold (float): The distance threshold (in kilometers) to determine if a vessel is close to a port.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The dataframe with updated vessel_status for the suspicious cases.\n",
    "    \"\"\"\n",
    "    # Set vessel_status to 'unknown' where vessel_status is NaN\n",
    "    df['vessel_status'] = df['vessel_status'].fillna('unknown')\n",
    "    \n",
    "    # Set vessel_status to 'unknown' for moored/anchored with SOG > 0.2 or moving with SOG = 0\n",
    "    df.loc[\n",
    "        ((df['vessel_status'] == 'moored') & (df['sog'] > 0.1)) |\n",
    "        ((df['vessel_status'] == 'anchored') & (df['sog'] > 0.1)) |\n",
    "        ((df['vessel_status'] == 'moving') & (df['sog'] == 0)),\n",
    "        'vessel_status'\n",
    "    ] = 'unknown'\n",
    "    \n",
    "    # Vectorized distance calculation using geopy's geodesic function\n",
    "    def calculate_distance_vectorized(lat1, lon1, lat2, lon2):\n",
    "        distances = np.zeros(len(lat1))\n",
    "        for i in range(len(lat1)):\n",
    "            if not np.isnan(lat2[i]) and not np.isnan(lon2[i]):\n",
    "                distances[i] = geodesic((lat1[i], lon1[i]), (lat2[i], lon2[i])).km\n",
    "            else:\n",
    "                distances[i] = float('inf')  # If port information is missing, return a large distance\n",
    "        return distances\n",
    "\n",
    "    # Calculate distances to ports for rows with 'unknown' vessel_status\n",
    "    mask_unknown = (df['vessel_status'] == 'unknown')\n",
    "    distances_to_port = calculate_distance_vectorized(\n",
    "        df.loc[mask_unknown, 'latitude'].values,\n",
    "        df.loc[mask_unknown, 'longitude'].values,\n",
    "        df.loc[mask_unknown, 'portLatitude'].values,\n",
    "        df.loc[mask_unknown, 'portLongitude'].values\n",
    "    )\n",
    "    \n",
    "    # Assign the calculated distances only to the rows with 'unknown' status\n",
    "    df.loc[mask_unknown, 'distance_to_port'] = distances_to_port\n",
    "    \n",
    "    # Set 'unknown' status to 'moored' if the vessel is close to a port and SOG = 0\n",
    "    df.loc[\n",
    "        (df['vessel_status'] == 'unknown') & (df['distance_to_port'] <= distance_threshold) & (df['sog'] == 0),\n",
    "        'vessel_status'\n",
    "    ] = 'moored'\n",
    "\n",
    "    # Vectorized check for latitude/longitude consistency to determine movement\n",
    "    lat_diff = df['latitude'].diff().abs().fillna(0)\n",
    "    lon_diff = df['longitude'].diff().abs().fillna(0)\n",
    "    is_moving_prev_next = (lat_diff > 0.0001) | (lon_diff > 0.0001)\n",
    "    \n",
    "    # Forward-fill and backward-fill consistency to account for movement in previous and next rows\n",
    "    is_moving = is_moving_prev_next | is_moving_prev_next.shift(-1).fillna(False) | is_moving_prev_next.shift(1).fillna(False)\n",
    "    \n",
    "    # Set 'unknown' to 'moving' if latitude/longitude inconsistency detected\n",
    "    df.loc[\n",
    "        (df['vessel_status'] == 'unknown') & is_moving,\n",
    "        'vessel_status'\n",
    "    ] = 'moving'\n",
    "    \n",
    "    # Clean up intermediate distance column\n",
    "    df = df.drop(columns=['distance_to_port'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to your dataset\n",
    "baseDataset = impute_unknown_vessel_status(baseDataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f81dee-7c26-43d8-b004-2dd9e7969223",
   "metadata": {},
   "source": [
    "# We now find outliers for sog and impute new values on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "694aa9c7-d6fa-4c16-b1d9-f14130bf7ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_sog_outliers_with_vessel_status(df, sog_threshold=30):\n",
    "    \"\"\"\n",
    "    Handle SOG outliers based on time_diff and vessel status.\n",
    "    \"\"\"\n",
    "    sog_col = 'sog'\n",
    "    vessel_col = 'vesselId'\n",
    "    time_diff_col = 'time_diff'\n",
    "    vessel_status_col = 'vessel_status'\n",
    "\n",
    "    # Calculate the median time_diff and SOG for moving vessels for each vessel\n",
    "    vessel_median_time_diff = df.groupby(vessel_col)[time_diff_col].transform('median')\n",
    "    vessel_median_moving_sog = df[df[vessel_status_col] == 'moving'].groupby(vessel_col)[sog_col].transform('median')\n",
    "\n",
    "    # Flag SOG outliers\n",
    "    df['sog_outlier'] = (df[sog_col] > sog_threshold).astype(int)\n",
    "\n",
    "    # Handle records based on vessel status\n",
    "    df.loc[(df['sog_outlier'] == 1) & (df[vessel_status_col] != 'moving'), sog_col] = 0\n",
    "\n",
    "    # Handle moving vessels by interpolating SOG where necessary\n",
    "    df.loc[(df['sog_outlier'] == 1) & (df[vessel_status_col] == 'moving') & (df[time_diff_col] <= vessel_median_time_diff), sog_col] = np.nan\n",
    "    \n",
    "    # Apply interpolation, ensuring vesselId doesn't become the index\n",
    "    df[sog_col] = df.groupby(vessel_col)[sog_col].apply(lambda group: group.interpolate(method='linear')).reset_index(level=0, drop=True)\n",
    "\n",
    "    # Impute SOG based on next time step's vessel status\n",
    "    def impute_sog(group):\n",
    "        for idx in group.index:\n",
    "            if pd.isnull(group.loc[idx, sog_col]) and group.loc[idx, time_diff_col] > vessel_median_time_diff.loc[idx]:\n",
    "                next_idx = group.index.get_loc(idx) + 1\n",
    "                if next_idx < len(group):\n",
    "                    next_status = group.iloc[next_idx][vessel_status_col]\n",
    "                    if next_status == 'moored':\n",
    "                        group.loc[idx, sog_col] = vessel_median_moving_sog.loc[idx]\n",
    "                    else:\n",
    "                        group.loc[idx, sog_col] = group[sog_col].bfill().iloc[0]\n",
    "        return group\n",
    "\n",
    "    # Apply imputation across vessels\n",
    "    df = df.groupby(vessel_col).apply(impute_sog).reset_index(drop=True)\n",
    "\n",
    "    # Drop intermediate column\n",
    "    df = df.drop(columns=['sog_outlier'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function to handle SOG outliers considering vessel status, time_diff, and gap flags\n",
    "baseDataset = handle_sog_outliers_with_vessel_status(baseDataset, sog_threshold=35)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51efc3-def2-4b01-a232-79e1b3084e1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "There are also outliers where sog is set to 0 which it obviously shouldn't be! So we fix this now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af2fc323-7173-423b-b71e-b212e4ee63f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def impute_sog_for_moving(df):\n",
    "    \"\"\"\n",
    "    Impute SOG values for 'moving' vessels with SOG = 0 by:\n",
    "    1. Checking future/previous SOG values for interpolation or filling.\n",
    "    2. Estimating speed based on distance between latitude/longitude when both SOG values are 0.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing SOG, vessel_status, latitude, longitude, and time_diff columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The dataframe with imputed SOG values for 'moving' vessels with SOG = 0.\n",
    "    \"\"\"\n",
    "    sog_col = 'sog'\n",
    "    vessel_status_col = 'vessel_status'\n",
    "    time_diff_col = 'time_diff'\n",
    "    vessel_col = 'vesselId'\n",
    "    lat_col = 'latitude'\n",
    "    lon_col = 'longitude'\n",
    "    \n",
    "    # Mask to select rows where vessel is moving and SOG = 0\n",
    "    mask_moving_sog_zero = (df[vessel_status_col] == 'moving') & (df[sog_col] == 0)\n",
    "    \n",
    "    # Step 1: Interpolate or fill SOG values where possible\n",
    "    def fill_sog_with_neighbors(group):\n",
    "        # Interpolate where possible (linear)\n",
    "        group[sog_col] = group[sog_col].replace(0, np.nan)\n",
    "        group[sog_col] = group[sog_col].interpolate(method='linear', limit_direction='both')\n",
    "        # Forward/Backward fill if interpolation can't be applied\n",
    "        group[sog_col] = group[sog_col].fillna(method='ffill').fillna(method='bfill')\n",
    "        return group\n",
    "    \n",
    "    # Apply the function to fill missing SOG values (this works for when there's valid data nearby)\n",
    "    df.loc[mask_moving_sog_zero, sog_col] = df.groupby(vessel_col, group_keys=False).apply(fill_sog_with_neighbors)[sog_col]\n",
    "    \n",
    "    # Step 2: For remaining cases, estimate speed based on latitude/longitude and time_diff\n",
    "    remaining_zero_sog_mask = (df[sog_col] == 0) & (df[vessel_status_col] == 'moving')\n",
    "    \n",
    "    def calculate_speed_from_distance(row):\n",
    "        # Calculate distance from previous row (latitude/longitude)\n",
    "        prev_lat, prev_lon = row[lat_col].shift(1), row[lon_col].shift(1)\n",
    "        curr_lat, curr_lon = row[lat_col], row[lon_col]\n",
    "        dist = geodesic((prev_lat, prev_lon), (curr_lat, curr_lon)).km\n",
    "        # Estimate speed: distance / time_diff\n",
    "        speed = dist / (row[time_diff_col] / 60)  # time_diff in minutes\n",
    "        return speed\n",
    "\n",
    "    # Apply speed calculation only where SOG = 0 and vessel is moving\n",
    "    df.loc[remaining_zero_sog_mask, sog_col] = df.loc[remaining_zero_sog_mask].apply(calculate_speed_from_distance, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "baseDataset = impute_sog_for_moving(baseDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2212a97-4c7d-40d9-8421-60f06d2f9437",
   "metadata": {},
   "source": [
    "# We now fix cog values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7d3a201-daaf-45a4-b17c-511ba7fc7bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_cog_nan_with_interpolation(df):\n",
    "    \"\"\"\n",
    "    Impute COG values for moving vessels using interpolation, and handle moored vessels separately.\n",
    "    \"\"\"\n",
    "    cog_col = 'cog'               # COG column\n",
    "    vessel_status_col = 'vessel_status'  # Vessel status column (moving, moored, anchored)\n",
    "    vessel_col = 'vesselId'        # Vessel identifier column\n",
    "\n",
    "    # Ensure 'vesselId' is not an index\n",
    "    if vessel_col in df.index.names:\n",
    "        df = df.reset_index(drop=False)  # Use drop=False to keep existing columns intact\n",
    "\n",
    "    # Step 1: Set COG to 0 for moored vessels (stationary), as course is not meaningful\n",
    "    df.loc[df[vessel_status_col] == 'moored', cog_col] = 0\n",
    "    \n",
    "    # Step 2: Interpolate COG values for moving vessels\n",
    "    df[cog_col] = df.groupby(vessel_col)[cog_col].apply(lambda group: group.interpolate(method='linear')).reset_index(level=0, drop=True)\n",
    "\n",
    "    # Step 3: Forward fill any remaining NaN values (in case interpolation can't be applied, e.g., at start of series)\n",
    "    df[cog_col] = df.groupby(vessel_col)[cog_col].fillna(method='ffill')\n",
    "\n",
    "    # Step 4: Backward fill any remaining NaN values (in case interpolation can't be applied, e.g., at end of series)\n",
    "    df[cog_col] = df.groupby(vessel_col)[cog_col].fillna(method='bfill')\n",
    "\n",
    "    # Step 5: Ensure COG values are within the valid range [0, 360]\n",
    "    df[cog_col] = df[cog_col] % 360\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function to your dataset\n",
    "baseDataset = handle_cog_nan_with_interpolation(baseDataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d10c65f7-db39-4739-9a9a-e8fb7be64841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522033 entries, 0 to 1522032\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   time            1522033 non-null  datetime64[ns]\n",
      " 1   cog             1522033 non-null  float64       \n",
      " 2   sog             1522033 non-null  float64       \n",
      " 3   rot             1522033 non-null  float64       \n",
      " 4   heading         1517137 non-null  float64       \n",
      " 5   etaRaw          766797 non-null   datetime64[ns]\n",
      " 6   latitude        1522033 non-null  float64       \n",
      " 7   longitude       1522033 non-null  float64       \n",
      " 8   vesselId        1522033 non-null  object        \n",
      " 9   portId          1520418 non-null  object        \n",
      " 10  portLatitude    1520418 non-null  float64       \n",
      " 11  portLongitude   1520418 non-null  float64       \n",
      " 12  shippingLineId  1522033 non-null  object        \n",
      " 13  CEU             1522033 non-null  int64         \n",
      " 14  DWT             1522033 non-null  float64       \n",
      " 15  GT              1522033 non-null  int64         \n",
      " 16  vesselType      1522033 non-null  category      \n",
      " 17  breadth         1522033 non-null  float64       \n",
      " 18  homePort        1522033 non-null  object        \n",
      " 19  length          1522033 non-null  float64       \n",
      " 20  age             1522033 non-null  int64         \n",
      " 21  time_diff       1522033 non-null  float64       \n",
      " 22  large_gap_flag  1522033 non-null  int64         \n",
      " 23  vessel_status   1522033 non-null  object        \n",
      "dtypes: category(1), datetime64[ns](2), float64(12), int64(4), object(5)\n",
      "memory usage: 268.5+ MB\n"
     ]
    }
   ],
   "source": [
    "baseDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6342d2-be0b-409c-a8a4-f8166bb2a393",
   "metadata": {},
   "source": [
    "# We now fix heading values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "929aafe4-2d44-4f02-b481-3a7e42c10c01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import atan2, radians, degrees, sin, cos\n",
    "\n",
    "def calculate_initial_compass_bearing(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the bearing between two points (lat1, lon1) and (lat2, lon2).\n",
    "    Returns the bearing in degrees (0° is north).\n",
    "    \"\"\"\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    x = sin(dlon) * cos(lat2)\n",
    "    y = cos(lat1) * sin(lat2) - sin(lat1) * cos(lat2) * cos(dlon)\n",
    "\n",
    "    initial_bearing = atan2(x, y)\n",
    "    initial_bearing = degrees(initial_bearing)\n",
    "    compass_bearing = (initial_bearing + 360) % 360\n",
    "\n",
    "    return compass_bearing\n",
    "\n",
    "def handle_heading_with_vessel_status(df):\n",
    "    \"\"\"\n",
    "    Handle heading missing values and anomalies based on time_diff, vessel status, and latitude/longitude.\n",
    "    \"\"\"\n",
    "    heading_col = 'heading'\n",
    "    vessel_col = 'vesselId'\n",
    "    time_diff_col = 'time_diff'\n",
    "    vessel_status_col = 'vessel_status'\n",
    "    lat_col = 'latitude'\n",
    "    lon_col = 'longitude'\n",
    "\n",
    "    # Step 1: Set heading to 0 for moored vessels\n",
    "    df.loc[df[vessel_status_col] == 'moored', heading_col] = 0\n",
    "\n",
    "    # Step 2: Calculate heading for rows with NaN based on consecutive lat/lon values\n",
    "    def calculate_heading_for_vessel(group):\n",
    "        for idx in group.index:\n",
    "            if pd.isnull(group.loc[idx, heading_col]):\n",
    "                next_idx = group.index.get_loc(idx) + 1\n",
    "                if next_idx < len(group):\n",
    "                    # Get current and next latitude/longitude\n",
    "                    curr_lat, curr_lon = group.loc[idx, lat_col], group.loc[idx, lon_col]\n",
    "                    next_lat, next_lon = group.iloc[next_idx][lat_col], group.iloc[next_idx][lon_col]\n",
    "                    \n",
    "                    # Calculate heading between current and next position\n",
    "                    if not (pd.isnull(curr_lat) or pd.isnull(curr_lon) or pd.isnull(next_lat) or pd.isnull(next_lon)):\n",
    "                        calculated_heading = calculate_initial_compass_bearing(curr_lat, curr_lon, next_lat, next_lon)\n",
    "                        group.loc[idx, heading_col] = calculated_heading\n",
    "                        \n",
    "        return group\n",
    "\n",
    "    # Apply the heading calculation function for vessels with missing heading values\n",
    "    df = df.groupby(vessel_col).apply(calculate_heading_for_vessel).reset_index(drop=True)\n",
    "\n",
    "    # Step 3: Use transform to apply forward and backward filling while preserving the index\n",
    "    df[heading_col] = df.groupby(vessel_col)[heading_col].transform(lambda group: group.ffill().bfill())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "baseDataset = handle_heading_with_vessel_status(baseDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d55369c4-0ed6-4d22-955a-e9c49e7b4615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522033 entries, 0 to 1522032\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   time            1522033 non-null  datetime64[ns]\n",
      " 1   cog             1522033 non-null  float64       \n",
      " 2   sog             1522033 non-null  float64       \n",
      " 3   rot             1522033 non-null  float64       \n",
      " 4   heading         1522033 non-null  float64       \n",
      " 5   etaRaw          766797 non-null   datetime64[ns]\n",
      " 6   latitude        1522033 non-null  float64       \n",
      " 7   longitude       1522033 non-null  float64       \n",
      " 8   vesselId        1522033 non-null  object        \n",
      " 9   portId          1520418 non-null  object        \n",
      " 10  portLatitude    1520418 non-null  float64       \n",
      " 11  portLongitude   1520418 non-null  float64       \n",
      " 12  shippingLineId  1522033 non-null  object        \n",
      " 13  CEU             1522033 non-null  int64         \n",
      " 14  DWT             1522033 non-null  float64       \n",
      " 15  GT              1522033 non-null  int64         \n",
      " 16  vesselType      1522033 non-null  category      \n",
      " 17  breadth         1522033 non-null  float64       \n",
      " 18  homePort        1522033 non-null  object        \n",
      " 19  length          1522033 non-null  float64       \n",
      " 20  age             1522033 non-null  int64         \n",
      " 21  time_diff       1522033 non-null  float64       \n",
      " 22  large_gap_flag  1522033 non-null  int64         \n",
      " 23  vessel_status   1522033 non-null  object        \n",
      "dtypes: category(1), datetime64[ns](2), float64(12), int64(4), object(5)\n",
      "memory usage: 268.5+ MB\n"
     ]
    }
   ],
   "source": [
    "baseDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c89d5-c3a4-4fb7-aa45-917fbb0346a2",
   "metadata": {},
   "source": [
    "## We now fix rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd63971a-f60c-475e-bfde-34c666364b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_rot_for_moored_vessels(df):\n",
    "    \"\"\"\n",
    "    Set ROT (Rate of Turn) to 0 for all moored vessels.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing vessel_behaviour and rot columns.\n",
    "    rot_col (str): The name of the ROT column.\n",
    "    behaviour_col (str): The name of the vessel behaviour column (e.g., 'moored', 'moving').\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The dataframe with ROT set to 0 for moored vessels.\n",
    "    \"\"\"\n",
    "    # Set ROT to 0 where vessel_behaviour is 'moored'\n",
    "    df.loc[df['vessel_status'] == 'moored', 'rot'] = 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "baseDataset = handle_rot_for_moored_vessels(baseDataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8839b9e-4c84-4660-848d-7f87b07a99cf",
   "metadata": {},
   "source": [
    "# We have now fixed all major issues. However, for our dataset to work on all types of ML models we will give the remaining missing values a value similar to \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df27be0f-3b79-40da-a101-850c39ed4cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    # For object (categorical or string) features, use 'unknown'\n",
    "    df['portId'] = df['portId'].fillna('unknown')\n",
    "    \n",
    "    # For datetime columns, use a placeholder date like '1970-01-01'\n",
    "    df['etaRaw'] = df['etaRaw'].fillna(pd.Timestamp('1970-01-01'))\n",
    "    \n",
    "    # For numeric columns, use an out-of-bounds value (e.g., -999)\n",
    "    df['portLatitude'] = df['portLatitude'].fillna(-999)\n",
    "    df['portLongitude'] = df['portLongitude'].fillna(-999)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to handle missing values in your dataset\n",
    "baseDataset = handle_missing_values(baseDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97d7c2c6-ee72-4f66-b5f5-31859baaa10d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522033 entries, 0 to 1522032\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   time            1522033 non-null  datetime64[ns]\n",
      " 1   cog             1522033 non-null  float64       \n",
      " 2   sog             1522033 non-null  float64       \n",
      " 3   rot             1522033 non-null  float64       \n",
      " 4   heading         1522033 non-null  float64       \n",
      " 5   etaRaw          1522033 non-null  datetime64[ns]\n",
      " 6   latitude        1522033 non-null  float64       \n",
      " 7   longitude       1522033 non-null  float64       \n",
      " 8   vesselId        1522033 non-null  object        \n",
      " 9   portId          1522033 non-null  object        \n",
      " 10  portLatitude    1522033 non-null  float64       \n",
      " 11  portLongitude   1522033 non-null  float64       \n",
      " 12  shippingLineId  1522033 non-null  object        \n",
      " 13  CEU             1522033 non-null  int64         \n",
      " 14  DWT             1522033 non-null  float64       \n",
      " 15  GT              1522033 non-null  int64         \n",
      " 16  vesselType      1522033 non-null  category      \n",
      " 17  breadth         1522033 non-null  float64       \n",
      " 18  homePort        1522033 non-null  object        \n",
      " 19  length          1522033 non-null  float64       \n",
      " 20  age             1522033 non-null  int64         \n",
      " 21  time_diff       1522033 non-null  float64       \n",
      " 22  large_gap_flag  1522033 non-null  int64         \n",
      " 23  vessel_status   1522033 non-null  object        \n",
      "dtypes: category(1), datetime64[ns](2), float64(12), int64(4), object(5)\n",
      "memory usage: 268.5+ MB\n"
     ]
    }
   ],
   "source": [
    "baseDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ba0ed-8c1f-42b5-838d-ebd7bc4c799e",
   "metadata": {},
   "source": [
    "# We now move onto feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecddbb0-7bcf-41a4-a4a4-ae168289a011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
